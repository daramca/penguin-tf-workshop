{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uQZeFdMkEWzW"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/torresmateo/penguin-tf-workshop/blob/master/ejercicios/D2_E1_MNIST_conv.ipynb\" target=\"_parent\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "\n",
    "\n",
    "# Convolutional MNIST\n",
    "\n",
    "En este notebook de ejercicios, vamos a mejorar el modelo que usamos para MNIST. La mejora consistirá en agregar primeramente más *layers* al modelo. Luego, un segundo modelo que use un *layer* de convolución. Finalmente, vamos a comparar la calidad de los dos modelos durante el entrenamiento y la evaluación.\n",
    "\n",
    "Por conveniencia, se incluye gran parte del código, además de funciones para visualizar mejor la evaluación de los modelos.\n",
    "\n",
    "**Importante**: Antes de correr el código en este notebook, elija un nuevo tipo de *Runtime*:\n",
    "1. Haga click en *Runtime* en el menú de arriba.\n",
    "2. *Change runtime type*\n",
    "3. Elija *GPU*\n",
    "4. Click en *SAVE*\n",
    "\n",
    "Esto reiniciará el *runtime* y será considerablemente más rápido el entrenamiento de los modelos convolucionales.\n",
    "\n",
    "Primeramente, se incluyen las bibliotecas necesarias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "7G6NqhQ-ETrm",
    "outputId": "ac588685-7921-41a1-ada6-86d808133208"
   },
   "outputs": [],
   "source": [
    "%tensorflow_version 2.x\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('default')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3Mk1Eb51LSLL"
   },
   "source": [
    "# Funciones de ayuda\n",
    "\n",
    "en la siguiente celda, se proveen varias funciones que servirán para entender las diferencias entre los modelos y comparar su rendimiento. Como en casos anteriores, es recomendable que al terminar los ejercicios se estudie este código para entender cómo monitorear el rendimiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F2E-8S_GLQs5"
   },
   "outputs": [],
   "source": [
    "def ver_historia(historia, titulo = '', ax = None):\n",
    "    \"\"\"\n",
    "    Visualizar una la historia de un modelo, \n",
    "    se hará una figura que muestre la evolución de la\n",
    "    función de costo y de la precisión del modelo con\n",
    "    respecto a los epochs.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    historia : keras History\n",
    "        Es lo que retorna la llamada a `model.fit`\n",
    "    titulo : str\n",
    "        el título del ax de arriba\n",
    "    ax : np.array\n",
    "        si se provee, no se creará una imagen nueva y se usará\n",
    "        `ax` en su lugar. Se debe proveer 2 ejes de una figura\n",
    "        de pyplot.\n",
    "    \"\"\"\n",
    "    create = ax is None\n",
    "    if create:\n",
    "        fig, ax = plt.subplots(2,1,figsize=(10,8), dpi=100)\n",
    "    acc      = historia.history['accuracy']\n",
    "    val_acc  = historia.history['val_accuracy']\n",
    "    loss     = historia.history['loss']\n",
    "    val_loss = historia.history['val_loss']\n",
    "    epochs = range(len(acc))\n",
    "    ax[0].grid(True)\n",
    "    ax[0].plot(epochs, acc, label=f\"Entrenamiento - {titulo}\")\n",
    "    ax[0].plot(epochs, val_acc, label=f\"Evaluación - {titulo}\")\n",
    "    ax[0].set_ylabel('Precisión')\n",
    "    ax[0].set_xlabel('Epoch')\n",
    "    ax[0].legend()\n",
    "    ax[1].grid(True)\n",
    "    ax[1].plot(epochs, loss, label=f\"Entrenamiento - {titulo}\")\n",
    "    ax[1].plot(epochs, val_loss, label=f\"Evaluación - {titulo}\")\n",
    "    ax[1].set_ylabel('Costo')\n",
    "    ax[1].set_xlabel('Epoch')\n",
    "    ax[1].legend()\n",
    "    if create:\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kyOLK1FhTNY-"
   },
   "source": [
    "# Ejercicio 1 - Carga y normalización del dataset\n",
    "\n",
    "Por conveniencia, se carga el *dataset* en variables de entrenamiento que se usarán más adelante.\n",
    "En este ejercicio, simplemente tienes que normalizar estas variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "ePSXzkUJTePs",
    "outputId": "d4669d53-3ee9-4ab9-9ea5-576b447de4f2"
   },
   "outputs": [],
   "source": [
    "(train_imgs, train_labels), (test_imgs, test_labels) = tf.keras.datasets.mnist.load_data()\n",
    "# normalizar las imágenes de entrenamiento y testing \n",
    "# tu código aquí (~2 líneas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VDdBbKsmTAY4"
   },
   "source": [
    "# Ejercicio 1 - Recrear el modelo de MNIST\n",
    "\n",
    "En la siguiente celda, completa el código necesario para recrear el modelo. \n",
    "\n",
    "La línea de entrenamiento del modelo ya se provee. Esto es porque para monitorear el rendimiento del modelo, vamos a analizar el historial de valores de las funciones de pérdida y la métrica de precisión en cada *epoch*. la llamada a `model.fit` retorna este historial. Para poder medir el historial de validación, también le pasamos el *validation set* a `model.fit`, de esta manera, el entrenamiento y la evaluación se hacen al mismo momento y en una sola llamada. Si lo desea, puede agregar más *layers* a su modelo, y ver como esto impacta en el rendimiento del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "6hfIxWBYS4-2",
    "outputId": "b6c7c0e4-853c-4422-9008-00691690c9ac"
   },
   "outputs": [],
   "source": [
    "# crear el modelo\n",
    "model =  # tu código aquí (~3-8 líneas)\n",
    "\n",
    "# compilar el modelo\n",
    "# tu código aquí (~1 línea)\n",
    "\n",
    "# entrenar el modelo\n",
    "historia = model.fit(train_imgs, train_labels, validation_data=(test_imgs, test_labels), epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zY7ao85bVepv"
   },
   "source": [
    "Con el modelo entrenado, podemos visualizar el historial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 696
    },
    "colab_type": "code",
    "id": "gD6N4cyaVhtU",
    "outputId": "4ae3e4b3-7bab-4ddf-e1e5-15c37e74bc38"
   },
   "outputs": [],
   "source": [
    "ver_historia(historia, titulo='Dense')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oR7wyfIqXAbD"
   },
   "source": [
    "Hay que prestar atención a este historial. Note como el rendimiento durante el entrenamiento es considerablemente mejor que el rendimiento en la evaluación. Esto es normal, y es una de las evidencias del *overfitting*. Estamos aprendiendo a clasificar imágenes casi exclusivamente para el *training set*. Visualizar el rendimiento de esta manera nos ayuda a tomar una decisión razonable de cuando parar el entrenamiento para evitar el overfitting. Luego de terminar los siguientes ejercicios, pruebe incrementar el valor de `epochs` y analice con cuidado el historial de comportamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_vX2sugrXqD4"
   },
   "source": [
    "# Ejercicio 2 - crear un segundo modelo\n",
    "\n",
    "Es momento de agregar *layers* convolucionales a nuestro modelo. En la siguiente celda, cree un nuevo modelo en la variable `cnn_model` que tenga uno o más *layers* convolucionales. No elimine los *layers* que se proveen, pues ayudan para lidiar con el cambio de dimensionalidad de los datos. Inserte los *layers* convolucionales donde se indica.\n",
    "\n",
    "## El *layer* convolucional\n",
    "\n",
    "Un ejemplo de *layer* convolucional es el siguiente:\n",
    "\n",
    "```python\n",
    "tf.keras.layers.Conv2D(32, (3, 3), activation='relu')\n",
    "```\n",
    "esto indica un *layer* de 32 neuronas, con filtros de 3x3. \n",
    "\n",
    "Si lo desea, puede agregar *pooling layers* a su modelo. Es común intercalar *layers* convolucionales con pooling layers. Un ejemplo es el siguiente:\n",
    "\n",
    "```python\n",
    "tf.keras.layers.MaxPooling2D(2, 2)\n",
    "```\n",
    "\n",
    "esto indica que ese layer va a reducir la resolución de la imagen a la mitad. Estudie la diferencia de agregar el pooling en el tiempo de entrenamiento y diferencia de rendimiento.\n",
    "\n",
    "**Importante**: Los *layers* convolucionales son computacionalmente más costosos de entrenar, por lo que no agregue más de 5 *layers* convolucionales o el entrenamiento puede ser de hasta media hora!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "PKtKTc9CV4Il",
    "outputId": "de348b48-6ec3-4e34-b118-f8e2c97d7878"
   },
   "outputs": [],
   "source": [
    "# crear el modelo\n",
    "model2 = tf.keras.models.Sequential([tf.keras.layers.Reshape(input_shape=(28, 28), target_shape=(28, 28, 1)), \n",
    "                                    # tu código aquí (~3-8 líneas)\n",
    "                                    tf.keras.layers.Flatten(),\n",
    "                                    tf.keras.layers.Dense(128, activation='relu'), \n",
    "                                    tf.keras.layers.Dense(10, activation='softmax')])\n",
    "\n",
    "# compilar el modelo\n",
    "# tu código aquí (~1 línea)\n",
    "\n",
    "# entrenar el modelo\n",
    "historia2 = model2.fit(train_imgs, train_labels, validation_data=(test_imgs, test_labels), epochs=10, batch_size=100)# su código aquí (~1 línea)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Phlur0pnhISB"
   },
   "source": [
    "Ahora podemos analizar y comparar ambas historias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 696
    },
    "colab_type": "code",
    "id": "ZVcsQgzAZVCn",
    "outputId": "7712d273-215b-44f0-9c95-35af1379678c"
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2,1, figsize=(10, 8), dpi=100, sharey=True)\n",
    "ver_historia(historia, 'Dense', ax=axs)\n",
    "ver_historia(historia2, 'Convolucional', ax=axs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "urWN1EGEiyk3"
   },
   "source": [
    "Como es esperado, vemos que el rendimiento del modelo convolucional mejora el rendimiento de forma considerable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mTnV0w0XjPFM"
   },
   "source": [
    "# Visualizar los *layers* convolucionales.\n",
    "\n",
    "A partir de este punto, ya no hay ejercicios en este notebook, pero puedes explorar que tipo de *features* son extraidos por los diferentes *layers* convolucionales. \n",
    "\n",
    "Puedes ejecutar varias veces esta celda para ver diversas imágenes y diversos filtros convolucionales aplicados. No es simple determinar con exactitud cuál de los filtros es el responsable de la mejora en performance de la red neuronal, y explicar el \"razonamiento\" de una red neuronal es un tema activo de investigación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 453
    },
    "colab_type": "code",
    "id": "bdyMX9OJanwR",
    "outputId": "0bd8a8fc-75d9-462f-d8bf-0403e3aaea64"
   },
   "outputs": [],
   "source": [
    "f, axarr = plt.subplots(3,4)\n",
    "imagenes=np.random.choice(len(test_imgs), 3)\n",
    "layer_outputs = [layer.output for layer in model2.layers]\n",
    "activation_model = tf.keras.models.Model(inputs = model2.input, outputs = layer_outputs)\n",
    "for x in range(0,4):\n",
    "    if x == 0:\n",
    "        axarr[0,x].imshow(test_imgs[imagenes[0]], cmap='gray_r')\n",
    "        axarr[0,x].set(title='Original')\n",
    "        axarr[1,x].imshow(test_imgs[imagenes[1]], cmap='gray_r')\n",
    "        axarr[2,x].imshow(test_imgs[imagenes[2]], cmap='gray_r')\n",
    "    else:\n",
    "        f1 = activation_model.predict(test_imgs[imagenes[0]].reshape(1, 28, 28))[x]\n",
    "        name = layer_outputs[x].name.split('/')[0]\n",
    "        conv = np.random.choice(f1.shape[-1])\n",
    "        axarr[0,x].imshow(f1[0, : , :, conv])\n",
    "        axarr[0,x].set(title=f'Layer {x}\\n{name}')\n",
    "        f2 = activation_model.predict(test_imgs[imagenes[1]].reshape(1, 28, 28))[x]\n",
    "        conv = np.random.choice(f2.shape[-1])\n",
    "        axarr[1,x].imshow(f2[0, : , :, conv])\n",
    "        f3 = activation_model.predict(test_imgs[imagenes[2]].reshape(1, 28, 28))[x]\n",
    "        conv = np.random.choice(f3.shape[-1])\n",
    "        axarr[2,x].imshow(f3[0, : , :, conv])\n",
    "    for i in range(3):\n",
    "        axarr[i,x].grid(False)\n",
    "        axarr[i,x].get_xaxis().set_ticks([])\n",
    "        axarr[i,x].get_yaxis().set_ticks([])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NyOpcBwBhXqO"
   },
   "source": [
    "# Créditos\n",
    "\n",
    "Este notebook utiliza y modifica recursos del [tutorial de TensorFlow](https://www.tensorflow.org/tutorials/images/cnn) y está inspirado en contenido del curso online [TensorFlow in Practice](https://www.deeplearning.ai/tensorflow-in-practice/)."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "D2_E1_Fashion_MNIST_convolution.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
